{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosh-Gupta/AbstractNet/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs2FxEOoCNms",
        "colab_type": "code",
        "outputId": "b2a921d3-86e7-4c7e-aa49-ca9ff6b0e57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!pip install transformers --q\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 645kB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 42.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43IAVjB2CL8s",
        "colab_type": "code",
        "outputId": "b8b3720d-fd3c-4f7a-99b6-0384ad621a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "logger = tf.get_logger()\n",
        "logger.info(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-OfvsNRGV4t",
        "colab_type": "code",
        "outputId": "95a94415-ead9-4b47-f571-92d4d010afb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    logger.info('Running with TPUStrategy on TPU {} with {} cores '\n",
        "                .format(tpu.cluster_spec().as_dict()['worker'],\n",
        "                        strategy.num_replicas_in_sync))\n",
        "except Exception:\n",
        "    raise ValueError\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device='/cpu:0')\n",
        "    logger.warning('Failed initializing TPU! Running on CPU')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.112.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.57.112.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running with TPUStrategy on TPU ['10.57.112.122:8470'] with 8 cores \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running with TPUStrategy on TPU ['10.57.112.122:8470'] with 8 cores \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m_O2VPFCL9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextDataset(tf.data.Dataset):\n",
        "    feature = {}\n",
        "    for i in range(512):\n",
        "        feature['dim_' + str(i)] = tf.io.VarLenFeature(tf.int64)\n",
        "\n",
        "\n",
        "    def _parse_example(example_proto):\n",
        "        parsed_example_dict = tf.io.parse_single_example(example_proto, TextDataset.feature)\n",
        "        parsed_example = [tf.sparse.to_dense(parsed_example_dict['dim_'+str(i)]) for i in range(512)]\n",
        "        parsed_example = tf.transpose(tf.stack(parsed_example, axis=0), perm=[1, 0])\n",
        "        return parsed_example\n",
        "\n",
        "\n",
        "    def _construct_inputs(input_ids):\n",
        "        input_ids = tf.cast(input_ids, dtype=tf.int32)\n",
        "        num_papers = tf.shape(input_ids)[0]\n",
        "        idx_a = tf.random.uniform(minval=0, maxval=num_papers, shape=[], dtype=tf.int32)\n",
        "        input_a = tf.gather(input_ids, idx_a)\n",
        "        all_related_papers = tf.gather(input_ids, tf.where(\n",
        "            tf.logical_not(tf.reduce_all(tf.equal(input_ids, input_a), axis=-1)))[:, 0])\n",
        "\n",
        "        idx = tf.random.categorical(tf.zeros([1, num_papers-1], dtype=tf.float32), num_samples=4)[0]\n",
        "        input_b, input_c, input_d, input_e = tf.unstack(tf.gather(all_related_papers, idx),\n",
        "                                                        num=4,\n",
        "                                                        axis=0)\n",
        "        return input_a, input_b, input_c, input_d, input_e\n",
        "\n",
        "\n",
        "    def _parse_and_create_sample(example_proto):\n",
        "        input_ids = TextDataset._parse_example(example_proto)\n",
        "        sample = TextDataset._construct_inputs(input_ids)\n",
        "        positive_labels = tf.ones([1])\n",
        "        negative_labels = tf.ones([batch_size])\n",
        "        return sample, (negative_labels, positive_labels)\n",
        "    \n",
        "    def __new__(cls, tfrecords_pattern, epochs, batch_size):\n",
        "        _options = tf.data.Options()\n",
        "        _options.experimental_deterministic = False\n",
        "\n",
        "        tfrecords = tf.data.Dataset.list_files(tfrecords_pattern)\n",
        "        dataset = tfrecords.interleave(tf.data.TFRecordDataset,\n",
        "                                       cycle_length=4,\n",
        "                                       block_length=16,\n",
        "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        dataset = dataset.with_options(_options)\n",
        "        dataset = dataset.map(cls._parse_and_create_sample,\n",
        "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "        dataset = dataset.repeat(epochs)\n",
        "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "        return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlETgD76CL9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4 * strategy.num_replicas_in_sync\n",
        "epochs = 2\n",
        "lr = 1e-5\n",
        "\n",
        "dataset = TextDataset('tfrecords/*', epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5WrwDEACL9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dot_product(x, y, pairwise=False, name=None):\n",
        "    if pairwise:\n",
        "        x = tf.expand_dims(x, axis=1)\n",
        "    return tf.reduce_sum(tf.multiply(x, y), axis=-1, name=name, keepdims=not pairwise)\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    base_model = TFRobertaModel.from_pretrained('allenai/biomed_roberta_base', from_pt=True)\n",
        "    inputs = [tf.keras.Input(shape=[512], dtype=tf.int32, name='input_{}'.format(i),\n",
        "                             batch_size=batch_size) for i in ['a', 'b', 'c', 'd', 'e']]\n",
        "    outputs = [tf.reduce_mean(base_model(x)[0], axis=1) for x in inputs]\n",
        "\n",
        "    ff1 = tf.keras.layers.Dense(768, activation='tanh', name='ff1')\n",
        "    ff1_outputs = [ff1(x) for x in outputs]\n",
        "\n",
        "    mean_related_papers = tf.reduce_mean(tf.concat(ff1_outputs[1:], axis=1), axis=1, keepdims=True)\n",
        "    ff2 = tf.keras.layers.Dense(768, activation='tanh', name='ff2')\n",
        "    ff2_output = ff2(mean_related_papers)\n",
        "\n",
        "    negative_outputs = dot_product(ff1_outputs[0], ff1_outputs[0], pairwise=True, name='negative')\n",
        "    positive_outputs = dot_product(ff2_output, ff2_output, pairwise=False, name='positive')\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=[negative_outputs, positive_outputs])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b02Ylv_y7Tor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positive_loss(_, y_pred):\n",
        "    y_pred = tf.nn.sigmoid(y_pred)\n",
        "    y_true = tf.ones([batch_size//strategy.num_replicas_in_sync, 1])\n",
        "    return tf.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "\n",
        "def negative_loss(_, y_pred):\n",
        "    y_pred = tf.nn.softmax(y_pred)\n",
        "    y_true = tf.eye(batch_size//strategy.num_replicas_in_sync)\n",
        "    return tf.losses.categorical_crossentropy(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxQn4k8h8VQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_dict = {\n",
        "    'tf_op_layer_positive': positive_loss,\n",
        "    'tf_op_layer_negative': negative_loss\n",
        "}\n",
        "with strategy.scope():\n",
        "    model = get_model()\n",
        "    model.compile(loss=loss_dict, optimizer=tf.keras.optimizers.Adam(lr))\n",
        "\n",
        "    callbacks_list = [tf.keras.callbacks.ModelCheckpoint(model_dir + '/weights.{epoch:02d}', save_weights_only=True)]\n",
        "    model.fit(dataset, epochs=epochs, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmiLSacJB7Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}